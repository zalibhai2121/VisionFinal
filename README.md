# VisionFinal

Building a neural network that recognizes the American Sign Language (ASL) alphabet using Python, Open-CV, and Tensor-Flow.

Note, this project is harder than expected, especially when taking into account similar letters - even for letters that do not require motion. We have enjoyed learning bits of sign language though. Also, even though certain people made certain commits, a lot (and I mean a lot) of ideas are discussed and worked out in our group chat.

Tonight and tomorrow, I am going to look into how other ASL reading programs deal with "j" and "z" and also get some pictures in so we can start classifying the other alphabets

4/24 - the cameraClassify.py can detect a hand when put on the screen, kept the contours may help in classification, but do not know as of yet -- next step is to train data in classify.py file -- z

4/27 - created label maker for the nn, and started training data -- M
--- can use corner detection to help detect what alphabet we are using -- Z

5/02 - pair/mob programming commiting through zainabalibhai

5/7 - Working on adding camera input -- M

5/10 - I just remembered we were supposed to update this as we go.... Guess who forgot??? Whoops --G
